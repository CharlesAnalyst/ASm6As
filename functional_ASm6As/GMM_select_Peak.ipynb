{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-evaluation",
   "metadata": {},
   "source": [
    "#### GMM_select peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "preceding-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_causalSNP(snv, si_list):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    # si = np.array([0.04,0.0900007,0.8064,0.0784,0.10240,0.04834,0.9804])\n",
    "    si = np.array(si_list)\n",
    "    X = np.reshape(si,(len(si),1))\n",
    "    # N = np.arange(1, NNN+1)\n",
    "    N = np.arange(1, 5) ### 不能超过样本的数目\n",
    "    models = [None for i in range(len(N))]\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        models[i] = mixture.GaussianMixture(N[i]).fit(X)\n",
    "    # compute the BIC\n",
    "    BIC = [m.bic(X) for m in models]\n",
    "    # best-fit mixture\n",
    "    M_best = models[np.argmin(BIC)] #### BIC最低的模型是最好的\n",
    "\n",
    "    # the largest peak in the distri\n",
    "    #  score: returns an array of Log probabilities of each data point in X\n",
    "    #  np.exp(logProb) => gives p(x) -> y-axis of the density or histogram\n",
    "    #  X: si numbers\n",
    "    logp = M_best.score_samples(X)\n",
    "    p = np.exp(logp)\n",
    "    maxP = np.argmax(p) #### index of largest prob\n",
    "    peakX = X[maxP][0]  #### maxP在X中对应的si值\n",
    "    nComp = M_best.n_components\n",
    "    labs =  M_best.predict(X)\n",
    "    peakComp = labs[maxP] #### component of largest si\n",
    "    ### peakX ~ peakComp\n",
    "\n",
    "    #randomly distribute the data points (评估background分布)\n",
    "    #discretize the x-axis to bins: https://stackoverflow.com/questions/31730028/how-can-i-generate-a-random-sample-of-bin-counts-given-a-sequence-of-bin-probabi\n",
    "    # nbin = BIN\n",
    "    nbin = 50\n",
    "    targBINindex = int(peakX*nbin)-1\n",
    "    bgprob = [0] + [1./nbin for i in range(nbin)] ### 均匀分布\n",
    "    # cdf = np.cumsum(bgprob)\n",
    "\n",
    "    thresh=[]\n",
    "    trials=500\n",
    "    for i in range(trials):\n",
    "        ## distributeBins (smartFunctions script): return bg list and bg (mean(bg) + variance(bg));\n",
    "        ## targBINindex bin中data point的数目\n",
    "        thresh.append(int(math.ceil(distributeBins(nbin,len(si),bgprob,targBINindex)[1])))\n",
    "\n",
    "    # het = res[(snv, exon, tag)]['0/1'] + res[(snv, exon, tag)]['1/0']\n",
    "    # tot = res[(snv, exon, tag)]['0/0'] + het + res[(snv, exon, tag)]['1/1']\n",
    "\n",
    "    # do for all components\n",
    "    # To decide whether the peakX is close to Si = 0 or 1\n",
    "    # calculate the z-score of 0 or 1 to the peak component's mean\n",
    "    zs, ps, means, stdevs, pns, ratios = [], [], [], [], [], []\n",
    "    for i in range(nComp): ## 三个成分\n",
    "        peakM = X[labs == i] ## 每一个成分对应的Si\n",
    "        peakMn = len(peakM)  ## 每个成分包含数据点的个数\n",
    "        mean = np.mean(peakM)\n",
    "        stdev = np.std(peakM, dtype=np.float64)\n",
    "        z0 = (0 - mean)/stdev\n",
    "        p0 = sp.stats.norm.sf(abs(z0))*2 #twosided\n",
    "        z1 = (1 - mean)/stdev\n",
    "        p1 = sp.stats.norm.sf(abs(z1))*2 #twosided\n",
    "        means.append(str(round(mean,4)))\n",
    "        stdevs.append(str(round(stdev,4)))\n",
    "        pns.append(str(peakMn))\n",
    "\n",
    "    #     ### rm.bg ###\n",
    "        thispeak = defaultdict(list) #len(p[labs == i])\n",
    "        try: ### ind作为thispeak这个dict的一个key(因为取整，所以会对应一系列相近的si数据点)\n",
    "            ### 这里取的是离mean最近的一个bin(是不是可以近似认为是包含mean的这个bin)；\n",
    "            ### 用这个bin代表整个si分布，去和background分布去比较；\n",
    "            ind = int(X[labs == i][np.argmin(abs(peakM-mean))][0]*nbin)\n",
    "        except ValueError:\n",
    "            zs.append('NA;NA')\n",
    "            ps.append('NA;NA')\n",
    "            continue\n",
    "        for xxx in X[labs == i]:\n",
    "            thispeak[int(xxx[0]*nbin)].append(xxx[0])\n",
    "\n",
    "        #real peak needs to be > than mean + 2.58 times the stdev (99% confidence intervals \n",
    "        # assuming 500 trials give us normal distri)\n",
    "        testingp = len(thispeak[ind])\n",
    "        if testingp <= np.mean(thresh) + 2.58*np.std(thresh, dtype=np.float64, axis=0):\n",
    "            zs.append('NA;NA')\n",
    "            ps.append('NA;NA')\n",
    "            continue\n",
    "        #############\n",
    "        ## \n",
    "        zs.append('{};{}'.format(z0,z1))\n",
    "        ps.append('{};{}'.format(p0,p1))\n",
    "    # out.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(snv,res[(snv,exon,tag)]['info'],exon,tag,\n",
    "    #         tot,res[(snv,exon,tag)]['0/0'],het,res[(snv,exon,tag)]['1/1'],peakX,\n",
    "    #         '|'.join(zs),'|'.join(ps),nComp,'|'.join(means),'|'.join(stdevs),'|'.join(pns)))\n",
    "    print(snv, peakX, '|'.join(zs),'|'.join(ps),nComp,'|'.join(means),'|'.join(stdevs),'|'.join(pns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

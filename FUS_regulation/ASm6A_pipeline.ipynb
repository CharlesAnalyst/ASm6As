{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. reads mapping && SNP calling && re-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/bam_wasp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. peak calling and remove m6Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/peak/merged_peak_MSPC/\"\n",
    "rm_m6Am = \"rm_m6Am\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SNP filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vcf_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/SNP_calling/\"\n",
    "vcf_dir = \"/Charles/project/ASm6A/shFUS/SNP_calling/06-CombinedVCF/\"\n",
    "os.chdir(vcf_dir)\n",
    "############################################################################\n",
    "\n",
    "#### select heterozygous SNP sites\n",
    "# ! ls */*_gatk.vcf | parallel 'cat {} | java -jar /home/software/snpEff/SnpSift.jar filter \"((countHet() > 0)\" > {.}_het.vcf'\n",
    "# ! ls */*_gatk_het.vcf | parallel \"/home/cjr/software/gatk-4.1.2.0/gatk SelectVariants -R /home/galaxy/project/alleleSpecific_analysis/data/hg19_genome/hg19.fa -V {} --select-type-to-include SNP --restrict-alleles-to BIALLELIC -O {.}_SNP.vcf\"\n",
    "\n",
    "### remove repeat && RNA editing\n",
    "repeat = \"/home/galaxy/project/alleleSpecific_analysis/data/RepeatMasker/RepeatMasker_hg19.record.bed\"\n",
    "editing = \"/home/galaxy/project/alleleSpecific_analysis/data/RNA_editing/Human_AG_all_hg19_v2.bed\"\n",
    "#\n",
    "result_dir = \"filtered_vcf/rm_repeat_editing/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "vcf_list = glob.glob(\"*_het_SNP.vcf\")\n",
    "for vcf in vcf_list:\n",
    "    result_file = os.path.join(result_dir, os.path.basename(vcf))\n",
    "    os.system(\"bedtools intersect -a %s -b %s %s -v -wa -header > %s\" % (vcf, repeat, editing, result_file))\n",
    "    \n",
    "#### overlapping with dbSNP\n",
    "# dbsnp = \"/home/galaxy/project/alleleSpecific_analysis/data/hg19_genome/dbsnp_138.hg19.bed\"\n",
    "dbsnp = \"/home/Data/database/hg38/dbsnp_146.hg19.bed\"\n",
    "base_dir = \"filtered_vcf/rm_repeat_editing/\"\n",
    "os.chdir(base_dir)\n",
    "result_dir = \"overlap_dbsnp/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "#\n",
    "vcf_list = glob.glob(\"*_het_SNP.vcf\") # ind1_gatk_het_SNP.vcf\n",
    "for vcf in vcf_list:\n",
    "    result_file = os.path.join(result_dir, os.path.basename(vcf))\n",
    "    os.system(\"bedtools intersect -a %s -b %s -wa -u -header > %s\" % (vcf, dbsnp, result_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt2\n",
      "kd\n",
      "kd2\n",
      "wt\n"
     ]
    }
   ],
   "source": [
    "### overlapping with m6A peak\n",
    "vcf_dir = \"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/vcf_dir/filtered_vcf/\"\n",
    "# vcf_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/SNP_calling/filtered_vcf/\"\n",
    "# vcf_dir = \"/Charles/project/ASm6A/shFUS/SNP_calling/06-CombinedVCF/filtered_vcf/\"\n",
    "os.chdir(vcf_dir)\n",
    "vcf_list = glob.glob(\"*.vcf\")\n",
    "result_dir = \"overlap_peak/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "##\n",
    "# peak_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/peak/merged_peak_MSPC/\"\n",
    "# peak_list = glob.glob(\"%s/*/ConsensusPeaks.bed\"%peak_dir) # ind1_gatk_het_SNP.vcf\n",
    "# peak_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/peak/merged_peak_MSPC/normalized_macs/\"\n",
    "peak_dir = \"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/peak/merged_peak_MSPC/normalized_macs/\"\n",
    "peak_list = glob.glob(\"%s/*.bed\" % peak_dir)\n",
    "#\n",
    "# vcf_list = glob.glob(\"*_het_SNP.vcf\") # ind1_gatk_het_SNP.vcf\n",
    "# for vcf in vcf_list:\n",
    "#     prefix = vcf.split(\"_het_SNP.vcf\")[0]\n",
    "#     peak = \"%s/%s/ConsensusPeaks.bed\" % (peak_dir, prefix)\n",
    "#     result_file = os.path.join(result_dir, \"%s_gatk.vcf\"%prefix)\n",
    "#     os.system(\"bedtools intersect -a %s -b %s -wa -u -header > %s\" % (vcf, peak, result_file))\n",
    "sample_dict = {\"wt\": \"Nc1\", \"wt2\": \"NC\", \"kd\": \"Fus2\", \"kd2\": \"Fus\"}\n",
    "for peak in peak_list:\n",
    "#     prefix = peak.split(\"/\")[-2]\n",
    "    prefix = os.path.basename(peak).split(\".bed\")[0]\n",
    "    print(prefix)\n",
    "#     vcf = \"%s/inp_het_SNP.vcf\" % (vcf_dir)\n",
    "    vcf = [x for x in vcf_list if x.split(\"-\")[0] == sample_dict[prefix]][0]\n",
    "    result_file = os.path.join(result_dir, vcf)\n",
    "    os.system(\"bedtools intersect -a %s -b %s -wa -u -header > %s\" % (vcf, peak, result_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Allele reads count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify the address of the VCF file\n",
    "# count_dir = \"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/count/readCount.sh\"\n",
    "# vcf_dir = \"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/SNP_calling/filtered_vcf/overlap_peak/\"\n",
    "vcf_dir = \"/Charles/project/ASm6A/shFUS/SNP_calling/06-CombinedVCF/filtered_vcf/overlap_peak/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. post filters and Hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galaxy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201 1501\n",
      "1499\n",
      "2200 1489\n",
      "1488\n",
      "1735 1069\n",
      "1068\n",
      "1201 448\n",
      "448\n",
      "1710 1049\n",
      "1047\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from multiprocessing import Pool\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "# os.chdir(\"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/count/\")\n",
    "# os.chdir(\"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/count/\")\n",
    "# os.chdir(\"/Charles/project/ASm6A/shFUS/SNP_calling/08-Count/\")\n",
    "os.chdir(\"/Charles/mjy/210505_A00869_0471_BH3NHMDSX2/count/\")\n",
    "# os.chdir(\"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/count/\")\n",
    "# sample_list = [\"wt\", \"kd\", \"wt2\", \"kd2\"]\n",
    "# file_list = [[\"Nc1-ip_L4_711D01.readcounts.txt\", \"Nc1-inp_L4_709D01.readcounts.txt\"],\n",
    "#              [\"Fus2-ip_L4_712D01.readcounts.txt\", \"Fus2-inp_L4_710D01.readcounts.txt\"],\n",
    "#              [\"NC-IP_L1_706D07.readcounts.txt\", \"NC-inp_L1_704D07.readcounts.txt\"],\n",
    "#              [\"Fus-IP_L1_707D07.readcounts.txt\", \"Fus-inp_L1_705D07.readcounts.txt\"]]\n",
    "# number_list = [[85184165, 78164647],\n",
    "#                [84298167, 68023740],\n",
    "#                [90201519, 46888237],\n",
    "#                [117018661, 59254724]]\n",
    "# sample_list = [\"wt1\", \"wt2\", \"kd1-1\", \"kd1-2\", \"kd2-1\", \"kd2-2\"]\n",
    "# file_list = [[\"IP1_L3_701D08.readcounts.txt\", \"inp1_L3_707D08.readcounts.txt\"],\n",
    "#              [\"IP2_L3_702D08.readcounts.txt\", \"inp2_L3_708D08.readcounts.txt\"],\n",
    "#              [\"IP3_L3_703D08.readcounts.txt\", \"inp3_L3_709D08.readcounts.txt\"],\n",
    "#              [\"IP4_L3_704D08.readcounts.txt\", \"inp4_L3_710D08.readcounts.txt\"],\n",
    "#              [\"IP5_L3_705D08.readcounts.txt\", \"inp5_L3_711D08.readcounts.txt\"],\n",
    "#              [\"IP6_L3_706D08.readcounts.txt\", \"inp6_L3_712D08.readcounts.txt\"]]\n",
    "# number_list = [[118311220, 23452971],\n",
    "#               [120152621, 27208576],\n",
    "#               [128702240, 28641536],\n",
    "#               [96370568, 31142454],\n",
    "#               [85093260, 24248087],\n",
    "#               [97331100, 24074659]]\n",
    "# sample_list = [\"wt1\", \"wt2\", \"kd1-1\", \"kd1-2\", \"kd2-1\", \"kd2-2\"]\n",
    "# file_list = [[\"wt1_m6A.readcounts.txt\", \"wt1_input.readcounts.txt\"],\n",
    "#              [\"wt2_m6A.readcounts.txt\", \"wt2_input.readcounts.txt\"],\n",
    "#              [\"kd1-1_m6A.readcounts.txt\", \"kd1-1_input.readcounts.txt\"],\n",
    "#              [\"kd1-2_m6A.readcounts.txt\", \"kd1-2_input.readcounts.txt\"],\n",
    "#              [\"kd2-1_m6A.readcounts.txt\", \"kd2-1_input.readcounts.txt\"],\n",
    "#              [\"kd2-2_m6A.readcounts.txt\", \"kd2-2_input.readcounts.txt\"]]\n",
    "# number_list = [[235340284, 98544569],\n",
    "#               [234933232, 114472977],\n",
    "#               [266382690, 108559562],\n",
    "#               [174853943, 148216516],\n",
    "#               [167459037, 116943118],\n",
    "#               [193237130, 112129516]]\n",
    "sample_list = [\"nc\", \"nc2\", \"T1\", \"T2\", \"T3\"]\n",
    "file_list = [[\"nc.readcounts.txt\", \"Input-nc.readcounts.txt\"],\n",
    "             [\"nc2.readcounts.txt\",\"Input-nc2.readcounts.txt\"],\n",
    "             [\"T1.readcounts.txt\", \"Input-t1.readcounts.txt\"],\n",
    "             [\"T2.readcounts.txt\", \"Input-t2.readcounts.txt\"],\n",
    "             [\"T3.readcounts.txt\", \"Input-t3.readcounts.txt\"]]\n",
    "#### WASP bam count\n",
    "number_list = [[130757272, 111377376],\n",
    "               [146388392, 107149644],\n",
    "               [147709422, 126380464],\n",
    "               [111946211, 43773006],\n",
    "               [81784485, 109386167]]\n",
    "# sample_list = [\"nc\", \"T1\", \"T2\", \"T3\"]\n",
    "# file_list = [[\"nc_ip.readcounts.txt\", \"nc_input.readcounts.txt\"],\n",
    "#              [\"T1_ip.readcounts.txt\", \"T1_input.readcounts.txt\"],\n",
    "#              [\"T2_ip.readcounts.txt\", \"T2_input.readcounts.txt\"],\n",
    "#              [\"T3_ip.readcounts.txt\", \"T3_input.readcounts.txt\"]]\n",
    "# #### WASP bam count\n",
    "# number_list = [[65373607, 55697999],\n",
    "#               [73850336, 63203740],\n",
    "#               [55975782, 21890844],\n",
    "#               [40891082, 54694449]]\n",
    "##########\n",
    "def preprocess_df(ip_file, input_file, totalNum_list):\n",
    "    df_ip, df_input = pd.read_table(ip_file), pd.read_table(input_file)\n",
    "    df_results = []\n",
    "    treat_list, df_list = ['ip', 'input'], [df_ip, df_input]\n",
    "    for i in range(len(df_list)):\n",
    "        df, treat, total_num = df_list[i], treat_list[i], totalNum_list[i]\n",
    "        df = df[[\n",
    "            'contig', 'position', 'refAllele', 'altAllele', 'refCount',\n",
    "            'altCount']]\n",
    "        df['#contig'] = df['contig']\n",
    "        del df['contig']\n",
    "        ###########################################################\n",
    "        if i == 0:  # ip sample: only restrict total number\n",
    "            df = df[(df['refCount'] + df['altCount']) >= 25] #####\n",
    "        else:\n",
    "            df = df[(df['refCount'] >= 5) & (df['altCount'] >= 5)]\n",
    "            df = df[(df['refCount'] + df['altCount']) >= 25] #####\n",
    "        ###########################################################\n",
    "        df['refCount_%s' % treat] = df['refCount']\n",
    "        df['altCount_%s' % treat] = df['altCount']\n",
    "        df['refRPKM_%s' % treat] = (df['refCount'] / total_num) * 1000000000\n",
    "        df['altRPKM_%s' % treat] = (df['altCount'] / total_num) * 1000000000\n",
    "        df_results.append(df)\n",
    "    return df_results[0], df_results[1]\n",
    "\n",
    "############ run\n",
    "result_dir = \"Hypothesis/Fisher/\" ####\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "for i in range(len(sample_list)):\n",
    "    result_file = os.path.join(result_dir, \"%s.txt\" % sample_list[i])\n",
    "    df_ip, df_input = preprocess_df(file_list[i][0], file_list[i][1], number_list[i])\n",
    "    print(len(df_ip), len(df_input))\n",
    "    df = df_ip.merge(df_input,\n",
    "                     on=['#contig', 'position', 'refAllele', 'altAllele'],\n",
    "                     how='left').dropna(how=\"any\")\n",
    "    print(len(df))\n",
    "    df['refRPKM_ratio'] = df['refRPKM_ip'] / df['refRPKM_input']\n",
    "    df['altRPKM_ratio'] = df['altRPKM_ip'] / df['altRPKM_input']\n",
    "    ## ref/(ref+alt)\n",
    "    df['allelicRatio'] = df['refRPKM_ratio'] / (df['altRPKM_ratio'] +\n",
    "                                                df['refRPKM_ratio'])\n",
    "    ## Fisher's exact test\n",
    "    pvalue_list, odds_list = [], []\n",
    "    for i, j in df.iterrows():\n",
    "        a, b = round(j['refRPKM_ip']) + 0.5, round(j['altRPKM_ip']) + 0.5\n",
    "        c, d = round(j['refRPKM_input']) + 0.5, round(j['altRPKM_input']) + 0.5\n",
    "        oddsratio, pvalue = stats.fisher_exact([[a, b], [c, d]])\n",
    "        pvalue_list.append(pvalue)\n",
    "        odds_list.append(oddsratio)\n",
    "    ## FDR correction\n",
    "    qvalue_list = list(fdrcorrection(pvalue_list)[1])\n",
    "    df['pvalue'], df['oddsratio'], df[\n",
    "        'qvalue'] = pvalue_list, odds_list, qvalue_list\n",
    "    df_sub = df[[\n",
    "        '#contig', 'position', 'refAllele', 'altAllele', 'refRPKM_ratio',\n",
    "        'altRPKM_ratio', 'allelicRatio', 'pvalue', 'oddsratio', 'qvalue',\n",
    "        'refCount_ip', 'altCount_ip', 'refCount_input', 'altCount_input'\n",
    "    ]]\n",
    "    df_sub.to_csv(result_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. pick out final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\n",
    "    # \"/Charles/project/ASm6A/shFUS/mapping/human/uniq_bam/count/Hypothesis/Fisher/\"\n",
    "#     \"/Charles/project/ASm6A/shFUS/SNP_calling/08-Count/Hypothesis/Fisher/\"\n",
    "#     \"/Charles/project/ASm6A/shFUS/SNP_calling/08-Count/Hypothesis/Fisher_2/\" #####\n",
    "#     \"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/count/Hypothesis/Fisher/\"\n",
    "    \"/Charles/mjy/210505_A00869_0471_BH3NHMDSX2/count/Hypothesis/Fisher/\"\n",
    ")\n",
    "# result_dir = \"filter/\"\n",
    "# os.system(\"mkdir -p %s\" % result_dir)\n",
    "txt_list = glob.glob(\"*.txt\")\n",
    "result_dir = \"sig/\"\n",
    "os.system(\"mkdir -p %s\" % result_dir)\n",
    "\n",
    "\n",
    "########\n",
    "def select_highFC(df, res):\n",
    "    #     bed_list = glob.glob(\"%s/*.bed\" % in_dir)\n",
    "    #     for asm6a in bed_list:\n",
    "    #     df = pd.read_table(in_file, header=None)\n",
    "    #     df.columns = ['contig', 'start', 'position', 'term', 'refRPKM_ratio', 'altRPKM_ratio']\n",
    "    # df['mark'] = df['term'].str.split(\";\").str[2]\n",
    "    df['mark'] = np.where((df['refRPKM_ratio'] > df['altRPKM_ratio']), \"ref\",\n",
    "                          \"alt\")\n",
    "    ##### unsig\n",
    "    df_u1 = df[df['qvalue'] >= 0.05]\n",
    "    df_u2 = df[(df['qvalue'] < 0.05)\n",
    "               & ((df['mark'] == \"ref\") & (df['refRPKM_ratio'] < 3))] ######\n",
    "    df_u3 = df[(df['qvalue'] < 0.05)\n",
    "               & ((df['mark'] == \"alt\") & (df['altRPKM_ratio'] < 3))] #######\n",
    "    df_unsig = pd.concat([df_u1, df_u2, df_u3])\n",
    "    df_unsig['mark'] = \"unsig\"\n",
    "    ##### sig\n",
    "    df_sig = df[df['qvalue'] < 0.05]\n",
    "    df_sig = df_sig[((df_sig['mark'] == \"ref\") &\n",
    "                     (df_sig['refRPKM_ratio'] >= 3)) | ############\n",
    "                    ((df_sig['mark'] == \"alt\") &\n",
    "                     (df_sig['altRPKM_ratio'] >= 3))]  ############\n",
    "    ##### merge and write to file\n",
    "    df = pd.concat([df_unsig, df_sig])\n",
    "    df.to_csv(res, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "\n",
    "for txt in txt_list:\n",
    "    df = pd.read_table(txt)\n",
    "    result_file = os.path.join(result_dir, txt)\n",
    "    select_highFC(df, result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### txt to bed\n",
    "# os.chdir(\"/Charles/project/ASm6A/shFUS/SNP_calling/08-Count/Hypothesis/Fisher/sig/\")\n",
    "# os.chdir(\"/Charles/project/ASm6A/shFUS/SNP_calling/08-Count/Hypothesis/Fisher_2/sig/\")\n",
    "# os.chdir(\"/home/galaxy/project/alleleSpecific_analysis/data/shFUS/count/Hypothesis/Fisher/sig/\")\n",
    "# os.chdir(\"/Charles/mjy/210505_A00869_0471_BH3NHMDSX2/count/Hypothesis/Fisher/sig/\")\n",
    "# txt_list = glob.glob(\"*.txt\")\n",
    "# for txt in txt_list:\n",
    "#     df = pd.read_table(txt, header=None)\n",
    "#     df = df[df.iloc[:,-1] != \"unsig\"] ####\n",
    "#     df['mark'] = df.iloc[:,-1]\n",
    "#     df['chr'] = df.iloc[:,0]\n",
    "#     df['s'] = df.iloc[:,1] - 1\n",
    "#     df['e'] = df.iloc[:,1]\n",
    "#     df[['chr','s','e','mark']].to_csv(txt.replace(\".txt\",\".bed\"), sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
